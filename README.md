ğŸ–ï¸ Speak & Point with GPT-4o

An Interpretability-Driven Gesture Interface for Multimodal AI Systems

Overview
This prototype explores how AI systemsâ€”particularly multimodal LLMs like GPT-4oâ€”can be directed through natural, physical gestures rather than traditional UI elements. Using MediaPipe hand tracking, camera input, and GPT-4oâ€™s image-text reasoning, it allows a user to point at a region and have the assistant interpret and respond to what the user is referencing.

â¸»

ğŸ¯ Why This Matters for Interpretability

LLMs are often opaque: users donâ€™t know what the model is attending to, why it gave a response, or how it connects inputs to outputs.
This project provides a physical interface layer that helps:
	â€¢	âœ… Localize user intent: By detecting where a user is pointing, we can spatially crop and isolate what theyâ€™re referring to.
	â€¢	âœ… Constrain model attention: By feeding GPT-4o a cropped image region, we help ground the assistantâ€™s focusâ€”mirroring interpretability ideas like saliency or Grad-CAM in vision models.
	â€¢	âœ… Bridge human-AI alignment: The assistant doesnâ€™t just process an image; itâ€™s guided by a natural human gesture. This opens the door to co-pilots that are physically contextual, not just linguistically smart.

â¸»

ğŸ§  Architecture
	â€¢	ğŸ“¸ st.camera_input() â€” Live image capture via Streamlit
	â€¢	âœ‹ MediaPipe Hands â€” Extracts fingertip position and detects pointing gestures
	â€¢	ğŸ“¦ Cropping logic â€” Extracts a region around the fingertip (context-aware attention proxy)
	â€¢	ğŸ§  GPT-4o â€” Receives a multimodal prompt: userâ€™s spoken intent + the image crop
	â€¢	ğŸ–¼ï¸ GPT Response â€” Shown side-by-side with the annotated image


ğŸ’¡ Use Cases
	â€¢	A kitchen assistant that responds to gestures like â€œwhat is this?â€ while pointing at an ingredient
	â€¢	A workshop tool that explains objects or instructions based on visual reference
	â€¢	A live demo scaffold for interpretability education: â€œwhat did the model focus on when I pointed here?â€

â¸»

ğŸ› ï¸ Built With
	â€¢	Python, Streamlit
	â€¢	MediaPipe (hand tracking)
	â€¢	OpenAI GPT-4o (Vision + Text)
	â€¢	PIL, NumPy, cv2